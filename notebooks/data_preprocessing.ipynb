{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b86b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, random\n",
    "\n",
    "from datasets import *\n",
    "\n",
    "TRAIN_CACHE = \"data/dataset_cache/dmresnet/train\"\n",
    "VAL_CACHE = \"data/dataset_cache/dmresnet/val\"\n",
    "TEST_CACHE = \"data/dataset_cache/dmresnet/test\"\n",
    "SEGMENT_TIME = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b6a5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio number: 10000\n",
      "Total train files: 8000\n",
      "Total validation files: 2000\n"
     ]
    }
   ],
   "source": [
    "audio_files = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/music/train-10k-30s/**/*.*\", recursive=True\n",
    ")\n",
    "audio_files = [f for f in audio_files if f.endswith(\".wav\")]\n",
    "print(f\"Total audio number: {len(audio_files)}\")\n",
    "random.seed(42)\n",
    "random.shuffle(audio_files)\n",
    "split_idx = int(0.8 * len(audio_files))\n",
    "train_files = audio_files[:split_idx]\n",
    "val_files = audio_files[split_idx:]\n",
    "print(f\"Total train files: {len(train_files)}\")\n",
    "print(f\"Total validation files: {len(val_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f170181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total musan music files: 660\n"
     ]
    }
   ],
   "source": [
    "audio_files_musan = glob.glob(\n",
    "    \"data/musan/music/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "audio_files_musan = [f for f in audio_files_musan if f.endswith(\".wav\")]\n",
    "print(f\"Total musan music files: {len(audio_files_musan)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fd79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test db: 500\n"
     ]
    }
   ],
   "source": [
    "test_doc = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/music/test-query-db-500-30s/db/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "test_doc = [f for f in test_doc if f.endswith(\".wav\")]\n",
    "print(f\"Total test db: {len(test_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4adc381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total background noise files: 3604\n"
     ]
    }
   ],
   "source": [
    "bg_noise_musan = glob.glob(\n",
    "    \"data/musan/noise/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "bg_noise_neural = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/aug/bg/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "bg_noise_musan = [f for f in bg_noise_musan if f.endswith(\".wav\")]\n",
    "bg_noise_neural = [f for f in bg_noise_neural if f.endswith(\".wav\")]\n",
    "bg_noise = bg_noise_musan + bg_noise_neural\n",
    "print(f\"Total background noise files: {len(bg_noise)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6316b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rir noise files: 440\n"
     ]
    }
   ],
   "source": [
    "rir_noise = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/aug/ir/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "rir_noise = [f for f in rir_noise if f.endswith(\".wav\")]\n",
    "print(f\"Total rir noise files: {len(rir_noise)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5484cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "augment = WaveformAugment(bg_noise_list=bg_noise, rir_noise_list=rir_noise)\n",
    "train_dataset_raw = MelSpecDataset(\n",
    "    train_files, split=\"train\", segment_sec=SEGMENT_TIME, augment=augment, device=device\n",
    ")\n",
    "val_dataset_raw = MelSpecDataset(val_files, split=\"val\", segment_sec=SEGMENT_TIME, device=device)\n",
    "test_dataset_raw = MelSpecDataset(test_doc, split=\"test\", segment_sec=SEGMENT_TIME, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f82701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache meta found. Loading sample paths from 'data/dataset_cache/dmresnet/train/meta.pt'...\n",
      "Resuming processing at sample 0 of 8000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: saved 100/8000 samples.\n",
      "Checkpoint reached: saved 200/8000 samples.\n",
      "Checkpoint reached: saved 300/8000 samples.\n",
      "Checkpoint reached: saved 400/8000 samples.\n",
      "Checkpoint reached: saved 500/8000 samples.\n",
      "Checkpoint reached: saved 600/8000 samples.\n",
      "Checkpoint reached: saved 700/8000 samples.\n",
      "Checkpoint reached: saved 800/8000 samples.\n",
      "Checkpoint reached: saved 900/8000 samples.\n",
      "Checkpoint reached: saved 1000/8000 samples.\n",
      "Checkpoint reached: saved 1100/8000 samples.\n",
      "Checkpoint reached: saved 1200/8000 samples.\n",
      "Checkpoint reached: saved 1300/8000 samples.\n",
      "Checkpoint reached: saved 1400/8000 samples.\n",
      "Checkpoint reached: saved 1500/8000 samples.\n",
      "Checkpoint reached: saved 1600/8000 samples.\n",
      "Checkpoint reached: saved 1700/8000 samples.\n",
      "Checkpoint reached: saved 1800/8000 samples.\n",
      "Checkpoint reached: saved 1900/8000 samples.\n",
      "Checkpoint reached: saved 2000/8000 samples.\n",
      "Checkpoint reached: saved 2100/8000 samples.\n",
      "Checkpoint reached: saved 2200/8000 samples.\n",
      "Checkpoint reached: saved 2300/8000 samples.\n",
      "Checkpoint reached: saved 2400/8000 samples.\n",
      "Checkpoint reached: saved 2500/8000 samples.\n",
      "Checkpoint reached: saved 2600/8000 samples.\n",
      "Checkpoint reached: saved 2700/8000 samples.\n",
      "Checkpoint reached: saved 2800/8000 samples.\n",
      "Checkpoint reached: saved 2900/8000 samples.\n",
      "Checkpoint reached: saved 3000/8000 samples.\n",
      "Checkpoint reached: saved 3100/8000 samples.\n",
      "Checkpoint reached: saved 3200/8000 samples.\n",
      "Checkpoint reached: saved 3300/8000 samples.\n",
      "Checkpoint reached: saved 3400/8000 samples.\n",
      "Checkpoint reached: saved 3500/8000 samples.\n",
      "Checkpoint reached: saved 3600/8000 samples.\n",
      "Checkpoint reached: saved 3700/8000 samples.\n",
      "Checkpoint reached: saved 3800/8000 samples.\n",
      "Checkpoint reached: saved 3900/8000 samples.\n",
      "Checkpoint reached: saved 4000/8000 samples.\n",
      "Checkpoint reached: saved 4100/8000 samples.\n",
      "Checkpoint reached: saved 4200/8000 samples.\n",
      "Checkpoint reached: saved 4300/8000 samples.\n",
      "Checkpoint reached: saved 4400/8000 samples.\n",
      "Checkpoint reached: saved 4500/8000 samples.\n",
      "Checkpoint reached: saved 4600/8000 samples.\n",
      "Checkpoint reached: saved 4700/8000 samples.\n",
      "Checkpoint reached: saved 4800/8000 samples.\n",
      "Checkpoint reached: saved 4900/8000 samples.\n",
      "Checkpoint reached: saved 5000/8000 samples.\n",
      "Checkpoint reached: saved 5100/8000 samples.\n",
      "Checkpoint reached: saved 5200/8000 samples.\n",
      "Checkpoint reached: saved 5300/8000 samples.\n",
      "Checkpoint reached: saved 5400/8000 samples.\n",
      "Checkpoint reached: saved 5500/8000 samples.\n",
      "Checkpoint reached: saved 5600/8000 samples.\n",
      "Checkpoint reached: saved 5700/8000 samples.\n",
      "Checkpoint reached: saved 5800/8000 samples.\n",
      "Checkpoint reached: saved 5900/8000 samples.\n",
      "Checkpoint reached: saved 6000/8000 samples.\n",
      "Checkpoint reached: saved 6100/8000 samples.\n",
      "Checkpoint reached: saved 6200/8000 samples.\n",
      "Checkpoint reached: saved 6300/8000 samples.\n",
      "Checkpoint reached: saved 6400/8000 samples.\n",
      "Checkpoint reached: saved 6500/8000 samples.\n",
      "Checkpoint reached: saved 6600/8000 samples.\n",
      "Checkpoint reached: saved 6700/8000 samples.\n",
      "Checkpoint reached: saved 6800/8000 samples.\n",
      "Checkpoint reached: saved 6900/8000 samples.\n",
      "Checkpoint reached: saved 7000/8000 samples.\n",
      "Checkpoint reached: saved 7100/8000 samples.\n",
      "Checkpoint reached: saved 7200/8000 samples.\n",
      "Checkpoint reached: saved 7300/8000 samples.\n",
      "Checkpoint reached: saved 7400/8000 samples.\n",
      "Checkpoint reached: saved 7500/8000 samples.\n",
      "Checkpoint reached: saved 7600/8000 samples.\n",
      "Checkpoint reached: saved 7700/8000 samples.\n",
      "Checkpoint reached: saved 7800/8000 samples.\n",
      "Checkpoint reached: saved 7900/8000 samples.\n",
      "Checkpoint reached: saved 8000/8000 samples.\n",
      "Processing complete. Meta saved to 'data/dataset_cache/dmresnet/train/meta.pt'.\n",
      "No cache meta found. Starting sample-wise preprocessing...\n",
      "Checkpoint reached: saved 100/2000 samples.\n",
      "Checkpoint reached: saved 200/2000 samples.\n",
      "Checkpoint reached: saved 300/2000 samples.\n",
      "Checkpoint reached: saved 400/2000 samples.\n",
      "Checkpoint reached: saved 500/2000 samples.\n",
      "Checkpoint reached: saved 600/2000 samples.\n",
      "Checkpoint reached: saved 700/2000 samples.\n",
      "Checkpoint reached: saved 800/2000 samples.\n",
      "Checkpoint reached: saved 900/2000 samples.\n",
      "Checkpoint reached: saved 1000/2000 samples.\n",
      "Checkpoint reached: saved 1100/2000 samples.\n",
      "Checkpoint reached: saved 1200/2000 samples.\n",
      "Checkpoint reached: saved 1300/2000 samples.\n",
      "Checkpoint reached: saved 1400/2000 samples.\n",
      "Checkpoint reached: saved 1500/2000 samples.\n",
      "Checkpoint reached: saved 1600/2000 samples.\n",
      "Checkpoint reached: saved 1700/2000 samples.\n",
      "Checkpoint reached: saved 1800/2000 samples.\n",
      "Checkpoint reached: saved 1900/2000 samples.\n",
      "Checkpoint reached: saved 2000/2000 samples.\n",
      "Processing complete. Meta saved to 'data/dataset_cache/dmresnet/val/meta.pt'.\n",
      "No cache meta found. Starting sample-wise preprocessing...\n",
      "Checkpoint reached: saved 100/500 samples.\n",
      "Checkpoint reached: saved 200/500 samples.\n",
      "Checkpoint reached: saved 300/500 samples.\n",
      "Checkpoint reached: saved 400/500 samples.\n",
      "Checkpoint reached: saved 500/500 samples.\n",
      "Processing complete. Meta saved to 'data/dataset_cache/dmresnet/test/meta.pt'.\n"
     ]
    }
   ],
   "source": [
    "train_data = preprocess_and_cache_lazy(train_dataset_raw, TRAIN_CACHE)\n",
    "val_data = preprocess_and_cache_lazy(val_dataset_raw, VAL_CACHE)\n",
    "test_data = preprocess_and_cache_lazy(test_dataset_raw, TEST_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52eb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
