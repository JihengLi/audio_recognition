{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9921,
     "status": "ok",
     "timestamp": 1742799020831,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "0jdxyJk73ZtA"
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1742793334907,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "maKnc2113b7R",
    "outputId": "4b6f28d8-4e80-4455-8f75-75cf76dc2128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio number: 150\n"
     ]
    }
   ],
   "source": [
    "audio_files = glob.glob(\n",
    "    \"../dataset/acrcloud/songkey/**/*.*\", recursive=True\n",
    ")\n",
    "audio_files = [f for f in audio_files if f.endswith(\".mp3\")]\n",
    "print(f\"Total audio number: {len(audio_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1742793336132,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "zGmfhKMe36rK",
    "outputId": "99cac764-90e9-499d-a4d9-ff525c96a6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio number: 351\n"
     ]
    }
   ],
   "source": [
    "query_files = glob.glob(\n",
    "    \"../dataset/acrcloud/parts2songkey/**/*.*\", recursive=True\n",
    ")\n",
    "query_files = [f for f in query_files if f.endswith(\".wav\")]\n",
    "print(f\"Total audio number: {len(query_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501097,
     "status": "ok",
     "timestamp": 1742793856666,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "AST_oXPp4OrW",
    "outputId": "ca90e254-5b33-472b-e86a-dc52dd186143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache file found. Starting dataset preprocessing...\n",
      "Checkpoint reached: processed 100 out of 351 samples.\n",
      "Checkpoint reached: processed 200 out of 351 samples.\n",
      "Checkpoint reached: processed 300 out of 351 samples.\n",
      "Processing complete. Cached dataset saved to '../dataset/dataset_cache/acrcloud_query_model2.pt'.\n",
      "No cache file found. Starting dataset preprocessing...\n",
      "Checkpoint reached: processed 100 out of 150 samples.\n",
      "Processing complete. Cached dataset saved to '../dataset/dataset_cache/acrcloud_doc_model2.pt'.\n"
     ]
    }
   ],
   "source": [
    "query_dataset_raw = MelSpecDataset(query_files)\n",
    "doc_dataset_raw = MelSpecDataset(audio_files)\n",
    "\n",
    "query_data = preprocess_and_cache(query_dataset_raw, \"../dataset/dataset_cache/acrcloud_query_model2.pt\")\n",
    "doc_data = preprocess_and_cache(doc_dataset_raw, \"../dataset/dataset_cache/acrcloud_doc_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 14734,
     "status": "ok",
     "timestamp": 1742799035638,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "iDhzi7mv6Zfx"
   },
   "outputs": [],
   "source": [
    "query_data = torch.load(\"../dataset/dataset_cache/acrcloud_query_model2.pt\")\n",
    "doc_data = torch.load(\"../dataset/dataset_cache/acrcloud_doc_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742799035643,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "5DZcfSfWBUEd"
   },
   "outputs": [],
   "source": [
    "query_dataset = CachedDataset(query_data)\n",
    "doc_dataset = CachedDataset(doc_data)\n",
    "\n",
    "query_loader = DataLoader(\n",
    "    query_dataset, batch_size=1, shuffle=False,\n",
    ")\n",
    "doc_loader = DataLoader(\n",
    "    doc_dataset, batch_size=1, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 192353,
     "status": "ok",
     "timestamp": 1742799886051,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "26Z0GsB18HUr",
    "outputId": "20ec80d9-3733-4f60-c16d-b379a98d0fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 150 document embeddings\n",
      "Epoch num: 1, Model accuracy is 0.1908831908831909\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 2, Model accuracy is 0.1623931623931624\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 3, Model accuracy is 0.24216524216524216\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 4, Model accuracy is 0.19943019943019943\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 5, Model accuracy is 0.21082621082621084\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 6, Model accuracy is 0.14814814814814814\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 7, Model accuracy is 0.2336182336182336\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 8, Model accuracy is 0.2849002849002849\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 9, Model accuracy is 0.33903133903133903\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 10, Model accuracy is 0.2621082621082621\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 11, Model accuracy is 0.18518518518518517\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 12, Model accuracy is 0.3475783475783476\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 13, Model accuracy is 0.2678062678062678\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 14, Model accuracy is 0.28774928774928776\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 15, Model accuracy is 0.2564102564102564\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 16, Model accuracy is 0.2934472934472934\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 17, Model accuracy is 0.25071225071225073\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 18, Model accuracy is 0.16524216524216523\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 19, Model accuracy is 0.2934472934472934\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 20, Model accuracy is 0.26495726495726496\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 21, Model accuracy is 0.2564102564102564\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 22, Model accuracy is 0.29914529914529914\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 23, Model accuracy is 0.19658119658119658\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 24, Model accuracy is 0.19658119658119658\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 25, Model accuracy is 0.27635327635327633\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 26, Model accuracy is 0.14814814814814814\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 27, Model accuracy is 0.22792022792022792\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 28, Model accuracy is 0.14245014245014245\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 29, Model accuracy is 0.20797720797720798\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 30, Model accuracy is 0.3247863247863248\n",
      "Indexed 150 document embeddings\n",
      "Epoch num: 31, Model accuracy is 0.2792022792022792\n"
     ]
    }
   ],
   "source": [
    "def extract_base_name(file_path):\n",
    "    base = os.path.basename(file_path)\n",
    "    base_no_ext, _ = os.path.splitext(base)\n",
    "    parts = base_no_ext.split('.')\n",
    "    return parts[-1] if parts else base_no_ext\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DimensionMaskedResNet().to(device)\n",
    "for epoch in range(1, 32):\n",
    "    model.load_state_dict(torch.load(f\"./model_cache/model3_epoch{epoch}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    query_filenames = []\n",
    "    query_embs = []\n",
    "    with torch.no_grad():\n",
    "        for query_batch in query_loader:\n",
    "            query_feat, query_path = query_batch\n",
    "            query_feat = query_feat.to(device)\n",
    "            query_emb = model(query_feat)\n",
    "            query_embs.append(query_emb.cpu().numpy())\n",
    "            query_filenames.append(query_path[0])\n",
    "\n",
    "    doc_filenames = []\n",
    "    doc_embs = []\n",
    "    with torch.no_grad():\n",
    "        for doc_batch in doc_loader:\n",
    "            doc_feat, doc_path = doc_batch\n",
    "            doc_feat = doc_feat.to(device)\n",
    "            doc_emb = model(doc_feat)\n",
    "            doc_embs.append(doc_emb.cpu().numpy())\n",
    "            doc_filenames.append(doc_path[0])\n",
    "\n",
    "    query_embs = np.concatenate(query_embs, axis=0).astype(np.float32)\n",
    "    doc_embs = np.concatenate(doc_embs, axis=0).astype(np.float32)\n",
    "\n",
    "    dim = doc_embs.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(doc_embs)\n",
    "    print(f\"Indexed {index.ntotal} document embeddings\")\n",
    "\n",
    "    k = 10\n",
    "    D, I = index.search(query_embs, k)\n",
    "\n",
    "    TP = 0\n",
    "    num_queries = query_embs.shape[0]\n",
    "    for i in range(num_queries):\n",
    "        query_base = extract_base_name(query_filenames[i])\n",
    "        retrieved_bases = [extract_base_name(doc_filenames[idx]) for idx in I[i]]\n",
    "        # print(f\"Query {i} (base: {query_base}) Top-{k} Neighbors: {retrieved_bases}\")\n",
    "        if query_base in retrieved_bases:\n",
    "            TP += 1\n",
    "\n",
    "    print(f\"Epoch num: {epoch}, Model accuracy is {TP / num_queries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742617866648,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "WLG29uVI9PDM",
    "outputId": "83e302dd-8dd7-4169-f152-19e7fa2a2e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 150 document embeddings\n",
      "Model accuracy is 0.24786324786324787\n"
     ]
    }
   ],
   "source": [
    "dim = doc_embs.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(doc_embs)\n",
    "print(f\"Indexed {index.ntotal} document embeddings\")\n",
    "\n",
    "k = 10\n",
    "D, I = index.search(query_embs, k)\n",
    "\n",
    "TP = 0\n",
    "num_queries = query_embs.shape[0]\n",
    "for i in range(num_queries):\n",
    "    query_base = extract_base_name(query_filenames[i])\n",
    "    retrieved_bases = [extract_base_name(doc_filenames[idx]) for idx in I[i]]\n",
    "    # print(f\"Query {i} (base: {query_base}) Top-{k} Neighbors: {retrieved_bases}\")\n",
    "    if query_base in retrieved_bases:\n",
    "        TP += 1\n",
    "\n",
    "print(f\"Model accuracy is {TP / num_queries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i40_xc9LFbbW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPWtlSbjmS8FXERrvxs04Qm",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
