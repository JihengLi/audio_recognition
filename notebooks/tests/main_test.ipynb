{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i40hU4JLZn8_"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os, glob, random\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import faiss\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from models import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CachedDataset(cache_file=\"data/dataset_cache/model2/cached_test_model2.pt\")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn_dif_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ugp8Wf3M-JRh"
   },
   "outputs": [],
   "source": [
    "def process_test(model, epoch, top_k, device):\n",
    "    model.load_state_dict(torch.load(f\"outputs/ResNet+Attention/model3_epoch{epoch}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    test_doc_embs = []\n",
    "    test_query_embs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_loader:\n",
    "            query_feat_batch, doc_feat_batch = test_batch\n",
    "            query_feat_batch = query_feat_batch.to(device)\n",
    "            doc_feat_batch = doc_feat_batch.to(device)\n",
    "\n",
    "            query_emb = model(query_feat_batch)\n",
    "            doc_emb = model(doc_feat_batch)\n",
    "\n",
    "            test_query_embs.append(query_emb.cpu().numpy())\n",
    "            test_doc_embs.append(doc_emb.cpu().numpy())\n",
    "\n",
    "    test_query_embs = np.concatenate(test_query_embs, axis=0).astype(np.float32)\n",
    "    test_doc_embs = np.concatenate(test_doc_embs, axis=0).astype(np.float32)\n",
    "\n",
    "    dim = test_doc_embs.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(test_doc_embs)\n",
    "\n",
    "    D, I = index.search(test_query_embs, top_k)\n",
    "\n",
    "    TP = 0\n",
    "    num_queries = test_query_embs.shape[0]\n",
    "    for i in range(num_queries):\n",
    "        # print(f\"Query {i} Top-{top_k} Neighbors: {I[i]}\")\n",
    "        if i in I[i]:\n",
    "            TP += 1\n",
    "\n",
    "    print(f\"Epoch {epoch}: Model accuracy is {TP / num_queries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQfUFrg7gKMd"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DimensionMaskedResNet().to(device)\n",
    "\n",
    "for epoch in range(4, 32):\n",
    "    process_test(model, epoch, 1, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfBJ1WFqd5mi"
   },
   "source": [
    "## Test with Musan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1742844918385,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "Bxrx-_R-d37H",
    "outputId": "2b86240b-aa70-48fd-8531-0476d75d0f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total musan music files: 660\n"
     ]
    }
   ],
   "source": [
    "test_musan_full = glob.glob(\n",
    "    \"../dataset/musan/music/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "test_musan_full = [f for f in test_musan_full if f.endswith(\".wav\")]\n",
    "print(f\"Total musan music files: {len(test_musan_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RBF7_cqgMy-"
   },
   "outputs": [],
   "source": [
    "def split_audio(file_path, sample_rate, segment_duration, overlap):\n",
    "    audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    total_samples = len(audio)\n",
    "    seg_samples = segment_duration * sample_rate\n",
    "    step_samples = (segment_duration - overlap) * sample_rate\n",
    "\n",
    "    segments = []\n",
    "    for start in range(0, total_samples, step_samples):\n",
    "        end = start + seg_samples\n",
    "        segment = audio[start:end]\n",
    "        if len(segment) < seg_samples:\n",
    "            pad_length = seg_samples - len(segment)\n",
    "            segment = np.concatenate([segment, np.zeros(pad_length)])\n",
    "        segments.append(segment)\n",
    "        if end >= total_samples:\n",
    "            break\n",
    "    return segments\n",
    "\n",
    "output_dir = \"../dataset/musan_segments\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file_path in test_musan_full:\n",
    "    segments = split_audio(file_path, FS, segment_duration=30, overlap=5)\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    for i, seg in enumerate(segments):\n",
    "        output_file = os.path.join(output_dir, f\"{base_name}.seg{i+1}.wav\")\n",
    "        sf.write(output_file, seg, FS)\n",
    "    print(f\"Processed {file_path} into {len(segments)} segments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1742844942883,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "GIBBUdd9jQI7",
    "outputId": "d4782739-da8c-4594-a5ab-91206bf2c136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total musan segment files: 9898\n"
     ]
    }
   ],
   "source": [
    "test_musan_segment = glob.glob(\"../dataset/musan_segments/*.*\")\n",
    "test_musan_segment = [f for f in test_musan_segment if f.endswith(\".wav\")]\n",
    "print(f\"Total musan segment files: {len(test_musan_segment)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDbry0hmhJZL"
   },
   "outputs": [],
   "source": [
    "def extract_base_name(file_path):\n",
    "    base = os.path.basename(file_path)\n",
    "    base_no_ext, _ = os.path.splitext(base)\n",
    "    parts = base_no_ext.split(\".\")\n",
    "    return parts[-2] if len(parts) >= 2 else base_no_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7vxaNYDhQL_"
   },
   "outputs": [],
   "source": [
    "class Model2QueryDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_paths,\n",
    "        segment_seconds=SEGMENT_TIME,\n",
    "        sample_rate=FS,\n",
    "        num_queries=NUM_AUG_QUERIES,\n",
    "    ):\n",
    "        self.file_paths = file_paths\n",
    "        self.sample_rate = sample_rate\n",
    "        self.num_queries = num_queries\n",
    "        self.segment_samples = int(segment_seconds * sample_rate)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.file_paths[idx]\n",
    "        channels, _ = read(file)\n",
    "        waveform = channels[0]\n",
    "        total_len = waveform.shape[0]\n",
    "\n",
    "        queries = []\n",
    "        for _ in range(self.num_queries):\n",
    "            if total_len > self.segment_samples:\n",
    "                start = random.randint(0, total_len - self.segment_samples)\n",
    "            else:\n",
    "                start = 0\n",
    "            end = start + self.segment_samples\n",
    "            query_wave = waveform[start:end]\n",
    "            query_spec = transform_to_spectrogram_mel(query_wave)\n",
    "            queries.append(query_spec)\n",
    "\n",
    "        filename = extract_base_name(file)\n",
    "        return queries, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gtp2D54hj9UK"
   },
   "outputs": [],
   "source": [
    "query_dataset_raw = Model2QueryDataset(test_musan_full)\n",
    "# Doc Dataset can just use the one from ACRCloud part\n",
    "doc_dataset_raw = Model2TestDataset(test_musan_segment)\n",
    "\n",
    "query_data = preprocess_and_cache(\n",
    "    query_dataset_raw, \"../dataset/dataset_cache/musan/musan_query_model2.pt\"\n",
    ")\n",
    "doc_data = preprocess_and_cache(\n",
    "    doc_dataset_raw, \"../dataset/dataset_cache/musan/musan_doc_model2.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QZxlmiYA8aB"
   },
   "outputs": [],
   "source": [
    "query_data = torch.load(\"../dataset/dataset_cache/musan/musan_query_model2.pt\")\n",
    "doc_data = torch.load(\"../dataset/dataset_cache/musan/musan_doc_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCMB4SymqXzq"
   },
   "outputs": [],
   "source": [
    "query_dataset = CachedDataset(query_data)\n",
    "doc_dataset = CachedDataset(doc_data)\n",
    "\n",
    "query_loader = DataLoader(\n",
    "    query_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")\n",
    "doc_loader = DataLoader(doc_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDuqKVovqrV6"
   },
   "outputs": [],
   "source": [
    "def process_test(model, epoch, top_k):\n",
    "    model.load_state_dict(torch.load(f\"./model_cache/model3_epoch{epoch}.pth\"))\n",
    "    # model.load_state_dict(torch.load(f\"./model_cache/ResNet18.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    query_filenames = []\n",
    "    query_embs = []\n",
    "    with torch.no_grad():\n",
    "        for query_batch in query_loader:\n",
    "            query_feats, query_paths = query_batch\n",
    "            for i in range(NUM_AUG_QUERIES):\n",
    "                query_feat = query_feats[i].to(device)\n",
    "                query_emb = model(query_feat)\n",
    "                query_embs.append(query_emb.cpu().numpy())\n",
    "                query_filenames.append(query_paths[0])\n",
    "\n",
    "    doc_filenames = []\n",
    "    doc_embs = []\n",
    "    with torch.no_grad():\n",
    "        for doc_batch in doc_loader:\n",
    "            doc_feat, doc_path = doc_batch\n",
    "            doc_feat = doc_feat.to(device)\n",
    "            doc_emb = model(doc_feat)\n",
    "            doc_embs.append(doc_emb.cpu().numpy())\n",
    "            doc_filenames.append(doc_path[0])\n",
    "\n",
    "    query_embs = np.concatenate(query_embs, axis=0).astype(np.float32)\n",
    "    doc_embs = np.concatenate(doc_embs, axis=0).astype(np.float32)\n",
    "\n",
    "    dim = doc_embs.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(doc_embs)\n",
    "\n",
    "    # D, I = index.search(query_embs, top_k)\n",
    "\n",
    "    # TP = 0\n",
    "    # num_queries = query_embs.shape[0]\n",
    "    # for i in range(num_queries):\n",
    "    #     query_base = query_filenames[i]\n",
    "    #     retrieved_bases = [doc_filenames[idx] for idx in I[i]]\n",
    "    #     # print(f\"Query {i} (base: {query_base}) Top-{k} Neighbors: {retrieved_bases}\")\n",
    "    #     if query_base in retrieved_bases:\n",
    "    #         TP += 1\n",
    "\n",
    "    # print(f\"Epoch {epoch}: Model accuracy is {TP / num_queries}\")\n",
    "\n",
    "    D, I = index.search(query_embs, top_k * 2)\n",
    "\n",
    "    TP = 0\n",
    "    num_queries = query_embs.shape[0]\n",
    "    for i in range(num_queries):\n",
    "        query_filename = query_filenames[i]\n",
    "        distinct_retrieved = []\n",
    "        for idx in I[i]:\n",
    "            candidate = doc_filenames[idx]\n",
    "            if candidate not in distinct_retrieved:\n",
    "                distinct_retrieved.append(candidate)\n",
    "            if len(distinct_retrieved) >= top_k:\n",
    "                break\n",
    "        if query_filename in distinct_retrieved:\n",
    "            TP += 1\n",
    "\n",
    "    print(f\"Epoch {epoch}: Model accuracy is {TP / num_queries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75662,
     "status": "ok",
     "timestamp": 1742854775243,
     "user": {
      "displayName": "Jiheng Li",
      "userId": "01318088611642014975"
     },
     "user_tz": 300
    },
    "id": "zmPeeBY6kvi7",
    "outputId": "bf88090c-9153-493c-be45-6ad073e6fc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Model accuracy is 0.9904040404040404\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = ResNet18Model(embed_dim=EMBED_DIM, hidden_size=HIDDEN_LAYER).to(device)\n",
    "model = DimensionMaskedCNN().to(device)\n",
    "\n",
    "for epoch in range(1, 32):\n",
    "    process_test(model, 7, 10)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXsZSxQUmaCs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LoUkdRSQEbj4"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
