{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b86b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, random\n",
    "\n",
    "from datasets import *\n",
    "\n",
    "TRAIN_CACHE = \"data/dataset_cache/model2/cached_train_model2.pt\"\n",
    "VAL_CACHE = \"data/dataset_cache/model2/cached_val_model2.pt\"\n",
    "TEST_CACHE = \"data/dataset_cache/model2/cached_test_model2.pt\"\n",
    "SEGMENT_TIME = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b6a5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio number: 10000\n",
      "Total train files: 8000\n",
      "Total validation files: 2000\n"
     ]
    }
   ],
   "source": [
    "audio_files = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/music/train-10k-30s/**/*.*\", recursive=True\n",
    ")\n",
    "audio_files = [f for f in audio_files if f.endswith(\".wav\")]\n",
    "print(f\"Total audio number: {len(audio_files)}\")\n",
    "random.seed(42)\n",
    "random.shuffle(audio_files)\n",
    "split_idx = int(0.8 * len(audio_files))\n",
    "train_files = audio_files[:split_idx]\n",
    "val_files = audio_files[split_idx:]\n",
    "print(f\"Total train files: {len(train_files)}\")\n",
    "print(f\"Total validation files: {len(val_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f170181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total musan music files: 660\n"
     ]
    }
   ],
   "source": [
    "audio_files_musan = glob.glob(\n",
    "    \"data/musan/music/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "audio_files_musan = [f for f in audio_files_musan if f.endswith(\".wav\")]\n",
    "print(f\"Total musan music files: {len(audio_files_musan)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fd79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test db: 500\n"
     ]
    }
   ],
   "source": [
    "test_doc = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/music/test-query-db-500-30s/db/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "test_doc = [f for f in test_doc if f.endswith(\".wav\")]\n",
    "print(f\"Total test db: {len(test_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4adc381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total background noise files: 3604\n"
     ]
    }
   ],
   "source": [
    "bg_noise_musan = glob.glob(\n",
    "    \"data/musan/noise/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "bg_noise_neural = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/aug/bg/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "bg_noise_musan = [f for f in bg_noise_musan if f.endswith(\".wav\")]\n",
    "bg_noise_neural = [f for f in bg_noise_neural if f.endswith(\".wav\")]\n",
    "bg_noise = bg_noise_musan + bg_noise_neural\n",
    "print(f\"Total background noise files: {len(bg_noise)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6316b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rir noise files: 440\n"
     ]
    }
   ],
   "source": [
    "rir_noise = glob.glob(\n",
    "    \"data/neural-audio-fp-dataset/aug/ir/**/*.*\",\n",
    "    recursive=True,\n",
    ")\n",
    "rir_noise = [f for f in rir_noise if f.endswith(\".wav\")]\n",
    "print(f\"Total rir noise files: {len(rir_noise)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5484cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_raw = MelSpecDataset(\n",
    "    train_files, bg_noise, rir_noise, split=\"train\", segment_seconds=SEGMENT_TIME\n",
    ")\n",
    "val_dataset_raw = MelSpecDataset(val_files, split=\"val\", segment_seconds=SEGMENT_TIME)\n",
    "test_dataset_raw = MelSpecDataset(test_doc, split=\"test\", segment_seconds=SEGMENT_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f82701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache meta found. Starting sample-wise preprocessing...\n"
     ]
    }
   ],
   "source": [
    "train_data = preprocess_and_cache_lazy(train_dataset_raw, TRAIN_CACHE)\n",
    "val_data = preprocess_and_cache_lazy(val_dataset_raw, VAL_CACHE)\n",
    "test_data = preprocess_and_cache_lazy(test_dataset_raw, TEST_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ae3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache file found. Starting dataset preprocessing...\n",
      "Checkpoint reached: processed 100 out of 500 samples.\n",
      "Checkpoint reached: processed 200 out of 500 samples.\n",
      "Checkpoint reached: processed 300 out of 500 samples.\n",
      "Checkpoint reached: processed 400 out of 500 samples.\n",
      "Checkpoint reached: processed 500 out of 500 samples.\n",
      "Processing complete. Cached dataset saved to '../dataset/dataset_cache/model2/cached_test_model2.pt'.\n"
     ]
    }
   ],
   "source": [
    "test_dataset_raw = MelSpecDataset(test_doc, split=\"test\", segment_seconds=SEGMENT_TIME)\n",
    "test_data = preprocess_and_cache(test_dataset_raw, TEST_CACHE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
